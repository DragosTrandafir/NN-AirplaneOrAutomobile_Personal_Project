{
 "cells": [
  {
   "cell_type": "code",
   "id": "48bcfba7-288a-4942-8f58-1e891b14f8b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:49:02.203222Z",
     "start_time": "2025-02-20T19:48:49.987699Z"
    }
   },
   "source": [
    "import numpy as np # arrays & loading data\n",
    "import tensorflow as tf # for building neural networks\n",
    "from tensorflow.keras.models import Sequential  # model type that we will use\n",
    "from tensorflow.keras.layers import Dense # we will use Dense layers\n",
    "from sklearn.preprocessing import StandardScaler # z-score normalization \n",
    "\n",
    "# suppress warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(0)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "868cfa67-d697-4023-a143-43154e7bf0de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:50:43.737550Z",
     "start_time": "2025-02-20T19:50:41.708652Z"
    }
   },
   "source": [
    "# unpickle the data from the batch files in the CIFAR-10 dataset\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        data_batch_data = pickle.load(fo, encoding='bytes')\n",
    "    return data_batch_data\n",
    "\n",
    "# here we will add all the batches of data\n",
    "all_data=np.empty((1,3073))\n",
    "\n",
    "\n",
    "for i in range(1,6):\n",
    "    # save the data from each batch as a dictionary\n",
    "    data_batch_data = unpickle(f\"cifar-10-batches-py\\\\data_batch_{i}\")\n",
    "\n",
    "    # split the data using the keys\n",
    "    labels = np.array(data_batch_data[b'labels'])\n",
    "    data = np.array(data_batch_data[b'data'])\n",
    "\n",
    "    # form a column vector where only 0 and 1 are kept ( we need binary classification)\n",
    "    labels_zero_or_one = np.where((labels<2),labels,-1)\n",
    "    labels_zero_or_one = labels_zero_or_one.reshape(-1,1) \n",
    "    \n",
    "    # concatanate the previous labels column to the data\n",
    "    data_concatanated = np.concatenate((data,labels_zero_or_one),axis=1)\n",
    "    \n",
    "    # keep only the rows that have 0 or 1 as labels (those with -1 as labels are not important now)\n",
    "    data_final= data_concatanated[data_concatanated[:,-1]!=-1]\n",
    "\n",
    "    all_data= np.concatenate((all_data,data_final),axis=0)\n",
    "    \n",
    "all_data=all_data[1:] # remove the first row (it contains unimportant elements)\n",
    "\n",
    "print(all_data)\n",
    "print(all_data.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[170. 168. 177. ...  78.  80.   1.]\n",
      " [159. 150. 153. ...  17.  19.   1.]\n",
      " [202. 202. 204. ... 243. 243.   0.]\n",
      " ...\n",
      " [156. 155. 156. ... 162. 162.   0.]\n",
      " [189. 186. 185. ... 171. 171.   1.]\n",
      " [229. 236. 234. ... 162. 161.   1.]]\n",
      "(10000, 3073)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "c304cb63-30b9-4d65-8078-7491b9ce3a58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:50:54.018094Z",
     "start_time": "2025-02-20T19:50:53.762637Z"
    }
   },
   "source": [
    "X = all_data[:,:-1] # forming the input and output \n",
    "y = all_data[:,-1]\n",
    "\n",
    "y = np.expand_dims(y, axis=1) # make y 2D - the commands later will require it\n",
    "\n",
    "# split the data into TRAINING, CROSS-VALIDATION \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TRAINING SET - 80%, CV SET - 20%\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "\n",
    "print(f\"training input shape:{X_train.shape}\")\n",
    "print(f\"training output shape:{y_train.shape}\")\n",
    "print(f\"cv input shape:{X_cv.shape}\")\n",
    "print(f\"cv output shape:{y_cv.shape}\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training input shape:(8000, 3072)\n",
      "training output shape:(8000, 1)\n",
      "cv input shape:(2000, 3072)\n",
      "cv output shape:(2000, 1)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4903775b-147e-420d-bf5c-c2ba4f215ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:50:59.854723Z",
     "start_time": "2025-02-20T19:50:59.666409Z"
    }
   },
   "source": [
    "# each image has 3072 units (this is explained in more detail in the documentation in the link provided)\n",
    "\n",
    "# sequential model structure\n",
    "\n",
    "# we may CHANGE TO CONVOLUTIONAL in the future, as it is more efficient for images\n",
    "model= Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(3072,)), # input size\n",
    "        Dense(200,activation=\"sigmoid\", name=\"layer1\"),\n",
    "        Dense(120,activation=\"sigmoid\", name=\"layer2\"),\n",
    "        Dense(60,activation=\"sigmoid\", name=\"layer3\"),\n",
    "        Dense(15,activation=\"sigmoid\", name=\"layer4\"),\n",
    "        Dense(1,activation=\"sigmoid\", name=\"layer5\"),\n",
    "    ], name=\"binary_model\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "9ce49c4d-1fcc-4e89-8209-3ab7370c35c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:51:20.375278Z",
     "start_time": "2025-02-20T19:51:20.288144Z"
    }
   },
   "source": [
    "# see details about the activation of every layer and the form of the w and b parameters\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"binary_model\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"binary_model\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ layer1 (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m)            │       \u001B[38;5;34m614,600\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer2 (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m120\u001B[0m)            │        \u001B[38;5;34m24,120\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer3 (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m60\u001B[0m)             │         \u001B[38;5;34m7,260\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer4 (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m)             │           \u001B[38;5;34m915\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer5 (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m16\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,260</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">915</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m646,911\u001B[0m (2.47 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">646,911</span> (2.47 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m646,911\u001B[0m (2.47 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">646,911</span> (2.47 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "71e54190-35ba-459e-9b3a-56bd878db41d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:51:26.657400Z",
     "start_time": "2025-02-20T19:51:25.527251Z"
    }
   },
   "source": [
    "# applying z-score to all the training data & cv data - adjust the data based on its distribution for Adam to converge faster\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_scaled = standard_scaler.fit_transform(X_train)\n",
    "X_cv_scaled = standard_scaler.transform(X_cv) \n",
    "\n",
    "# define loss and optimizer of the Adam's algorithm\n",
    "model.compile(\n",
    "    # this is similar to gradient descent, but it is a much improved version\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), # BC - binary class \n",
    "    optimizer=tf.keras.optimizers.Adam(0.01), # preimplemented optimizer\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "90fceeaf-9b37-48ff-9673-649b1a43dce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:53:53.966756Z",
     "start_time": "2025-02-20T19:53:37.100933Z"
    }
   },
   "source": [
    "# train the model \"epochs\" times\n",
    "model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs = 10\n",
    "    \n",
    "    \n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - loss: 0.2879\n",
      "Epoch 2/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - loss: 0.3007\n",
      "Epoch 3/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - loss: 0.2991\n",
      "Epoch 4/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - loss: 0.2968\n",
      "Epoch 5/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - loss: 0.2884\n",
      "Epoch 6/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - loss: 0.2752\n",
      "Epoch 7/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - loss: 0.2877\n",
      "Epoch 8/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - loss: 0.2932\n",
      "Epoch 9/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step - loss: 0.2960\n",
      "Epoch 10/10\n",
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - loss: 0.2906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b5dd7d4ad0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "c164cbcf-6bec-40ef-9984-62be8161226e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:54:08.146782Z",
     "start_time": "2025-02-20T19:54:06.457597Z"
    }
   },
   "source": [
    "# fraction of misclassified outputs in the TRAINING SET\n",
    "y_predicted = model.predict(X_train_scaled)\n",
    "# classic way of calculating the error in a classification case\n",
    "y_predicted = np.where(y_predicted>=0.5,1,0)\n",
    "error_training = np.mean(y_predicted != y_train) # arithmetic mean, where the numerator is the count of wrong predictions\n",
    "print(f\"Training Set Classification Error: {error_training}\")\n",
    "\n",
    "# do the same for CV set\n",
    "y_predicted = model.predict(X_cv_scaled)\n",
    "y_predicted = np.where(y_predicted>=0.5,1,0)\n",
    "error_cv = np.mean(y_predicted != y_cv) \n",
    "print(f\"CV Set Classification Error: {error_cv}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m250/250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n",
      "Training Set Classification Error: 0.1205\n",
      "\u001B[1m63/63\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step\n",
      "CV Set Classification Error: 0.1705\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "61b52a46-41fd-4930-9546-f99653737415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:54:45.946098Z",
     "start_time": "2025-02-20T19:54:45.732485Z"
    }
   },
   "source": [
    "# save the test batch data \n",
    "test_batch_data = unpickle(\"cifar-10-batches-py\\\\test_batch\")\n",
    "\n",
    "# split the data using the keys\n",
    "labels = np.array(test_batch_data[b'labels'])\n",
    "data = np.array(test_batch_data[b'data'])\n",
    "\n",
    "# form a column vector where only 0 and 1 are kept ( we need binary classification)\n",
    "labels_zero_or_one = np.where((labels<2),labels,-1)\n",
    "labels_zero_or_one = labels_zero_or_one.reshape(-1,1) \n",
    "\n",
    "# concatanate the labels column form above to the data\n",
    "data_concatanated = np.concatenate((data,labels_zero_or_one),axis=1)\n",
    "\n",
    "# keep only the rows that have 0 or 1 as labels (those with -1 as labels are not important now)\n",
    "data_final= data_concatanated[data_concatanated[:,-1]!=-1]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "90c9a72a-ffc5-45f3-8128-8dae9a39bfb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:54:50.949769Z",
     "start_time": "2025-02-20T19:54:50.940220Z"
    }
   },
   "source": [
    "X = data_final[:,:-1] # forming the input and output \n",
    "y = data_final[:,-1]\n",
    "\n",
    "y_test = np.expand_dims(y, axis=1) # make y 2D - the commands later will require it"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "3bae2d4e-8538-4e7a-b1f3-0b077df44947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:54:52.705487Z",
     "start_time": "2025-02-20T19:54:52.655257Z"
    }
   },
   "source": [
    "X_test_scaled = standard_scaler.transform(X) "
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "fd64b14a-8ac6-4729-9002-549ff6579b79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T19:55:07.215698Z",
     "start_time": "2025-02-20T19:55:06.862382Z"
    }
   },
   "source": [
    "# fraction of misclassified outputs in the TEST SET\n",
    "y_predicted = model.predict(X_test_scaled)\n",
    "y_predicted = np.where(y_predicted>=0.5,1,0)\n",
    "error_test = np.mean(y_predicted != y_test) \n",
    "print(f\"Test Set Classification Error: {error_test}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m63/63\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "Test Set Classification Error: 0.1615\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de748d7-2afc-49f6-91dd-55502bb028e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
